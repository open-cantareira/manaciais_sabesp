{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ddddd\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem também esses dados aqui!\n",
    "\n",
    "mananciais.sabesp.com.br/api/Mananciais/ResumoTelemetricos/2020-04-01\n",
    "\n",
    "SYSTEM\n",
    "http://ssd3sabesp.labsid.eng.br/login.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Inicialmente importa-se as bibliotecas que serão necessárias para rodar os códigos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E é criada a estrutura de pastas que serão utilizadas para armazenar os arquivos que serão criados ao longo do processo. Em específico, a pasta *data* é a que armazenará a tabela com as informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../codes/files/create_folders.py'\n",
    "create_folders('', ['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Série Histórica e Datas\n",
    "\n",
    "A função abaixo retorna três parâmetros:\n",
    "1. Tabela com uma série histórica, com uma data de início e uma data de término.\n",
    "2. Data inicial em formato texto, para ser usada no nome do arquivo que vamos criar.\n",
    "3. Data final em formato texto, para ser usada no nome do arquivo que vamos criar.\n",
    "\n",
    "Caso não seja definida uma data final, será usado o dia de hoje.\n",
    "Importante ter atenção a isso pois a SABESP disponibiliza atualizações dos dados as 9:00 (conforme site deles) e, caso o presente código seja rodado entre a meia noite e as 9:00, tentar-se-á obter informações não disponíveis, possivelmnete gerando erros. Para contornar isso, é possível inserir um parâmetro como *dia de hoje - 1*, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tab(start='1970-1-1', end=None):\n",
    "    \"\"\"\n",
    "    Function to create date table, with only on colum named 'Data' as index.\n",
    "    With no 'end' parameter is passed, the function will return a table until today\n",
    "    With no 'start' parameter is passed, the function will return a table staring in firts day of de 70's.\n",
    "    \n",
    "    The function return two more parameters to used in filenames:\n",
    "    filename_start > first day of table \n",
    "    filename_end   > last day of table as string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Dataframe to get dates\n",
    "    if end is None:\n",
    "        df = pd.DataFrame(pd.date_range(pd.to_datetime(start), end=datetime.date.today()), columns=['Data'])\n",
    "        filename_start = str(datetime.datetime.strptime(str(start), '%Y-%m-%d').strftime('%Y.%m.%d'))\n",
    "        filename_end   = str(datetime.datetime.strptime(str(datetime.date.today()), '%Y-%m-%d').strftime('%Y.%m.%d'))\n",
    "    \n",
    "    else:\n",
    "        df = pd.DataFrame(pd.date_range(pd.to_datetime(start), end=pd.to_datetime(end)), columns=['Data'])\n",
    "        filename_start = str(datetime.datetime.strptime(str(start), '%Y-%m-%d').strftime('%Y.%m.%d'))\n",
    "        filename_end   = str(datetime.datetime.strptime(str(end), '%Y-%m-%d').strftime('%Y.%m.%d'))\n",
    "\n",
    "    # Results\n",
    "    df = df.set_index('Data')\n",
    "    return df, filename_start, filename_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2015-11-01'\n",
    "end = '2015-12-31'\n",
    "\n",
    "df_day, filename_start, filename_end = get_data_tab(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filename_start)\n",
    "print(filename_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Link* para fazer o *download* do Json\n",
    "\n",
    "Inicialmente foram feitas tentativas diversas para melhor conhecimento do [*site* da SABESP](http://mananciais.sabesp.com.br/HistoricoSistemas?SistemaId=0) que disponibiliza as informações dos mananciais. Inicialmente tentou-se obter os dados pela técnica de *web scrapping*, até que descobriu-se que os dados são distribuídos por meio de uma API do SSD (Sistema de Suporte a Decisões).\n",
    "\n",
    "Observou-se que a consulta manual apresenta os dados do mês da presente data até o primeiro dia do mês anterior. Por exemplo, se estamos no dia 25.**03**.2020, os dados apresentados serão dessa data até o dia 01.**02**.2020, retornando aproximadamente dados de 55 dias (30 dias de um mês hipotético e 25 do outro). O mesmo padrão irá ocorrer caso a consulta seja feita em 01.**03**.2020, a qual retornar-a os dados *até o primeiro dia do mês anterior*, ou seja, 01.**02**.2020.\n",
    "\n",
    "Essa forma de \"entregar\" os dados foi considerada na requisição de dados pela API, a qual foi feita com uso do [urllib.request](https://stackoverflow.com/questions/32795460/loading-json-object-in-python-using-urllib-request-and-json-modules). A API tem seu *link* padrão apresentado abaixo, sendo inserido apenas duas variáveis: a data e o Sistema (aqui representado pelo 0 no final, que representa o Sistema Produtor Cantareira).\n",
    "\n",
    "- http://mananciais.sabesp.com.br/api/Mananciais/RepresasSistemasNivel/2020-03-25/0\n",
    "\n",
    "*ToDo*: O Presente código tem a finalidade de obter os dados unicamente do Sistema Cantareira e, portanto, não se pensou em adicionar a possibilidade de obter os dados dos outros sistemas produtores, por meio da inclusão e ajuste desse parâmetro definido e fixado como *0*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = ('http://mananciais.sabesp.com.br/api/Mananciais/RepresasSistemasNivel/' + \n",
    "        str(filename_start.replace('.','-')) + '/' +\n",
    "        str(filename_end.replace('.','-')) + '/0')\n",
    "\n",
    "site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o *link* da API com uma data definida, criou-se uma função para obter os dados em formato *json*, bastanto inserir o site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url):\n",
    "    # Get Array with data\n",
    "    webURL = urllib.request.urlopen(site)\n",
    "    my_bytes = webURL.read()\n",
    "\n",
    "    # Transform Array into JSON\n",
    "    my_json = my_bytes.decode('utf8')\n",
    "    data = json.loads(my_json)\n",
    "    return json.dumps(data, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsn = get_json(site)\n",
    "#print(jsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertendo Json para tabela e extraíndo dados\n",
    "\n",
    "Com o arquivo Json contendo todos os dados de mais de um mês atrás, segmentado em diversas chaves e subchaves, iniciou-se a segmentação do arquivo, convertendo o arquivo para uma tabela, com a qual tenho mais familiaridade para editar e filtrar.\n",
    "\n",
    "A função abaixo tem essa aplicação e já aproveita para excluir duas colunas que, aparentemente, não agregam informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2table(jsn):\n",
    "    # Create dataframe\n",
    "    df = pd.read_json(jsn)\n",
    "\n",
    "    # Delete columns\n",
    "    return df.drop(['FlagHasError', 'Message'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = json2table(jsn)\n",
    "df_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema Produtor\n",
    "\n",
    "Por meio do campo *SistemaId* é possível obter o código que define qual é o sistema produtor de água. Contudo, considerando que o presente *script* visa obter somente os dados do Sistema Cantareira, **tal função não será aplicada**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.loc['SistemaId']['ReturnObj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Final\n",
    "\n",
    "Identifica data empregada na API, a partir da qual se obterá os dados *até o primeiro dia do mês anterior*. Não se vislumbra muita utilidade para essa informação nesse momento, tendo em vista que foi o usuário que definiu esse parâmetro na definição do *link* de acesso à API. Logo, **tal função não será aplicada**.\n",
    "\n",
    "Cabe ressaltar que tal função é chamada em outras funções, para se obter a data do último registro da tabela, qu poderá, ou não, ser excluído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enddate(df):\n",
    "    # JSON to dataframe    \n",
    "    data = df_json.loc['DataFinal']['ReturnObj']   \n",
    "    \n",
    "    # Results\n",
    "    return pd.to_datetime(data, dayfirst=True).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_enddate(df_json)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_startdate(df):\n",
    "    # JSON to dataframe    \n",
    "    data = df_json.loc['DataInicial']['ReturnObj']   \n",
    "    \n",
    "    # Results\n",
    "    return pd.to_datetime(data, dayfirst=True).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_startdate(df_json)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manobras Operacionais\n",
    "\n",
    "Identifica todas as manobras listadas no site da SABESP. São dados mais descritivos, disponibilizados visando dar mais transparência a cadeia de comando para abrir ou fechar os reservatórios. Nesse primeiro momento tais dados não serão analisado e, portanto, **tal função não será aplicada**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manobras(df):\n",
    "    # JSON to dataframe    \n",
    "    lst = df.loc['ListaManobras']['ReturnObj']\n",
    "    \n",
    "    # Results\n",
    "    return pd.json_normalize(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_manobras = get_manobras(df_json)\n",
    "#df_manobras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes do Sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservatórios\n",
    "\n",
    "A função abaixo lista os reservatórios (ou represas) do Sistema Cantareira e outras que estão integradas, de alguma maneira, ao Sistema, inserindo também o identificador de cada reservatório (*ComponenteId*).\n",
    "\n",
    "Apesar de trata-se de uma tabela que não retorna dados temporais (por exemplo: vazão, volume e chuva), ou seja, que variam ao longo do tempo, é fundamental para rotular de qual reservatório que são os dados temporais que serão obtidos nas próximas funções, visto que eles se valem, majoritariamente, do campo *ComponenteId*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst = df_json.loc['ListaRepresas']['ReturnObj']\n",
    "#df = pd.json_normalize(lst)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_represas(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaRepresas']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "\n",
    "    # Delete columns\n",
    "    df = df.drop(['temChuva','temNivel', 'temQjus', 'temQnat', 'temVolume'], axis=1)\n",
    "\n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_represas = list_represas(df_json)\n",
    "#tab_represas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estruturas (Túneis e outros Pontos de Medição)\n",
    "\n",
    "A função abaixo lista os túneis e estações de monitoramento do Sistema Cantareira e outras que estão integradas, de alguma maneira, ao Sistema, inserindo também o identificador de cada local (*ComponenteId*).\n",
    "\n",
    "Apesar de trata-se de uma tabela que não retorna dados temporais (por exemplo: vazão, volume e chuva), ou seja, que variam ao longo do tempo, contudo é fundamental para rotular de qual estrutura que são os dados temporais que serão obtidos nas próximas funções, visto que eles se valem, majoritariamente, do campo *ComponenteId* ou *abreviatura*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_estruturas(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaLocais']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "\n",
    "    # Delete columns\n",
    "    df = df.drop(['Maximo','Minimo',\n",
    "                  'Data','Dia',\n",
    "                  'Valor','Unidade'],\n",
    "                 axis=1)\n",
    "\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('ComponenteId')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_estruturas = list_estruturas(df_json)\n",
    "#tab_estruturas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Diários\n",
    "\n",
    "Nessa seção que serão obtidos diversos dados relevantes na operação do Sistema Cantareira, tais como:\n",
    "- Vazão natural em cada reservatório;\n",
    "- Vazão afluente em cada reservatório;\n",
    "- Vazão defluente em cada reservatório;\n",
    "- Nível e Volume de cada reservatório;\n",
    "- Dados de Precipitação de cada reservatório.\n",
    "\n",
    "Inicialmente, definiu-se uma função para renomear *strings*, visto que estas constarão nos cabeçalhos das tabelas a serem criadas. Aplicou-se a função na *tab_represas* (criada acima) apenas para observar quais serão os nomes que constarão no cabeçalho das tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_field(x):\n",
    "    return(x.replace('/', '-').\n",
    "           replace(' (', '-').\n",
    "           replace(')', '').\n",
    "           replace('Cesp', 'CESP').\n",
    "           replace('Represa ', '').\n",
    "           replace(' ', '')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = tab_represas\n",
    "#t['Nome_Header'] = t['Nome'].apply(lambda x: rename_field(x))\n",
    "#t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume, QJusante e Chuva\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDados* e subchave *Dados*, foi obtido os dados de volume, vazão defluente e precpitação de cada reservatório.\n",
    "\n",
    "No arquivo json, as tabelas encontravam-se empilhadas (*flat table*), com uma coluna com o nome do reservatório. Portanto, foi necessário filtrar essas tabelas por reservatório, ajustar o cabeçalho inserindo o nome do reservatório em questão e, posteriromente, fazer um join das tabelas pelo campo *data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_volumes(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDados']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Dados')\n",
    "\n",
    "    # Define pivot to create new tables\n",
    "    fields = df['Nome']\n",
    "    fields = sorted(list(set(fields)))\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('Data')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Create a blank table\n",
    "    df_full,start,end = get_data_tab()\n",
    "\n",
    "    for i in fields:\n",
    "        # Define Nomes e Nomes de Tabelas\n",
    "        j = rename_field(i)\n",
    "        tab_name = 'tab_dados' + '_' + j\n",
    "        \n",
    "        # Filtra e cria das tabelas por fields (represas)\n",
    "        locals()[tab_name] = df[df['Nome'] == i]\n",
    "\n",
    "        # Deleta colunas\n",
    "        locals()[tab_name] = locals()[tab_name].drop(['FlagConsolidado',\n",
    "                                                      'NAMaxMax','NAMinMin',\n",
    "                                                      'QJusanteMax','QJusanteMin',\n",
    "                                                      'NivelUltimoDia',\n",
    "                                                      'SistemaId','ComponenteId',\n",
    "                                                      'UltimoDia',\n",
    "                                                      'VazaoJusantePrincipal','VazaoJusanteSecundaria',\n",
    "                                                      'VolumeOperacionalUltimoDia','VolumePorcentagemUltimoDia',\n",
    "                                                      'VolumeTotalUltimoDia','Nome'], axis=1)\n",
    "\n",
    "        # Renomeia as colunas\n",
    "        locals()[tab_name].columns = [x if x=='Data' else j+'_'+x for x in locals()[tab_name].columns]\n",
    "\n",
    "        # Convert Data Column (object) to datatime colum\n",
    "        locals()[tab_name]['Data'] = pd.to_datetime(locals()[tab_name]['Data'])\n",
    "\n",
    "        # Merge all tables\n",
    "        df_full = pd.merge(df_full,locals()[tab_name],on='Data',how='left')\n",
    "\n",
    "    # Results\n",
    "    df_full = df_full.set_index('Data')\n",
    "    df_full.dropna(how='all', inplace=True)\n",
    "    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_volumes = list_volumes(df_json)\n",
    "#display(tab_volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vazão Afluente e Vazão Natural\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDados* e subchave *Qnat*, foram obtido os dados de vazão afluente e vazão naturalde cada reservatório.\n",
    "\n",
    "No arquivo json, as tabelas encontravam-se empilhadas (*flat table*), com uma coluna com o nome do reservatório. Portanto, foi necessário filtrar essas tabelas por reservatório, ajustar o cabeçalho inserindo o nome do reservatório em questão e, posteriromente, fazer um join das tabelas pelo campo *data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vazao(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDados']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Qnat')\n",
    "\n",
    "    # Merge Tables\n",
    "    df = pd.merge(df, tab_represas, on='ComponenteId', how='outer')\n",
    "\n",
    "    # Define pivot to create new tables\n",
    "    fields = df['Nome']\n",
    "    fields = sorted(list(set(fields)))\n",
    "    \n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('Data')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Create a blank table\n",
    "    df_full,start,end = get_data_tab()\n",
    "\n",
    "    for i in fields:\n",
    "        # Define Nomes e Nomes de Tabelas\n",
    "        j = rename_field(i)\n",
    "        tab_name = 'tab_vazaonatural'+'_'+j\n",
    "        \n",
    "        # Filtra e cria das tabelas por fields (represas)\n",
    "        locals()[tab_name] = df[df['Nome'] == i]\n",
    "\n",
    "        # Deleta colunas\n",
    "        locals()[tab_name] = locals()[tab_name].drop(['ComponenteId','Nome',\n",
    "                                                      'VazaoAfluenteMax','VazaoAfluenteMin',\n",
    "                                                      'VazaoNaturalMax','VazaoNaturalMin'],axis=1)\n",
    "\n",
    "        # Renomeia as colunas\n",
    "        locals()[tab_name].columns = [x if x=='Data' else j+'_'+x for x in locals()[tab_name].columns]\n",
    "\n",
    "        # Convert Data Column (object) to datatime colum\n",
    "        locals()[tab_name]['Data'] = pd.to_datetime(locals()[tab_name]['Data'])\n",
    "\n",
    "        # Merge all tables\n",
    "        df_full = pd.merge(df_full,locals()[tab_name], on='Data', how='left')\n",
    "\n",
    "    # Results\n",
    "    df_full = df_full.set_index('Data')\n",
    "    df_full.dropna(how='all', inplace=True)\n",
    "    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_vazao = list_vazao(df_json)\n",
    "#display(tab_vazao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sistema Equivalente\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDados*, foram obtido os dados do Sistema Equivalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_SE(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDados']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "\n",
    "    # Delete columns\n",
    "    df = df.drop(['Dados','Data','Qnat'], axis=1)\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "\n",
    "    # Functions to rename\n",
    "    col = ['SE_'+x for x in col]\n",
    "    col = [x.replace('SistemaEquivalente.', '').replace('SE_Data', 'Data') for x in col]\n",
    "\n",
    "    # Rename Columns\n",
    "    df.columns = col\n",
    "\n",
    "    # Convert Data Column (object) to datatime colum\n",
    "    df['Data'] = pd.to_datetime(df['Data'])\n",
    "\n",
    "    # Results\n",
    "    df = df.set_index('Data')\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_SE = list_SE(df_json)\n",
    "#display(tab_SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vazão dos Túneis e outros Pontos de Medição\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDadosLocais* e subchave *Dados*, foram obtido os dados de vazão dos túneis Q7, Q6 Q5 e outros.\n",
    "\n",
    "No arquivo json, as tabelas encontravam-se empilhadas (*flat table*), com uma coluna com o nome da estrutura. Portanto, foi necessário filtrar essas tabelas por estrutura, adicionando ao cabeçalho seu repectivo nome e, posteriormente, fazer um join das tabelas pelo campo *data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vazaoestruturas(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDadosLocais']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Dados')\n",
    "\n",
    "    # Define pivot to create new tables\n",
    "    fields = df['Abreviatura']\n",
    "    fields = sorted(list(set(fields)))\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('Data')))\n",
    "    col.append(col.pop(col.index('Unidade')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Create a blank table\n",
    "    df_full,start,end = get_data_tab()\n",
    "\n",
    "    for i in fields:\n",
    "        # Define Nomes e Nomes de Tabelas\n",
    "        j = rename_field(i)\n",
    "        tab_name = 'tab_dados' + '_' + j\n",
    "        \n",
    "        # Filtra e cria das tabelas por fields (represas)\n",
    "        locals()[tab_name] = df[df['Abreviatura'] == i]\n",
    "\n",
    "        # Deleta colunas\n",
    "        locals()[tab_name] = locals()[tab_name].drop(['Maximo', 'Minimo', 'Dia', 'Abreviatura', 'ComponenteId', 'LocalMedicaoId', 'Nome', 'SistemaId'],axis=1)\n",
    "\n",
    "        # Renomeia as colunas\n",
    "        locals()[tab_name].columns = [x if x=='Data' else j+'_'+x for x in locals()[tab_name].columns]\n",
    "\n",
    "        # Convert Data Column (object) to datatime colum\n",
    "        locals()[tab_name]['Data'] = pd.to_datetime(locals()[tab_name]['Data'])\n",
    "\n",
    "        # Merge all tables\n",
    "        df_full = pd.merge(df_full,locals()[tab_name],on='Data',how='left')\n",
    "\n",
    "    # Results\n",
    "    df_full = df_full.set_index('Data')\n",
    "    df_full.dropna(how='all', inplace=True)\n",
    "    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_vazaoestruturas = list_vazaoestruturas(df_json)\n",
    "#display(tab_vazaoestruturas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Horários\n",
    "\n",
    "Referem-se a transposição da bacia do rio Paraíba do Sul para a bacia do rio Piracicaba, por meio da Estação Elevatória de Água Bruta (EEAB) Jaguari, que despeja água na represa Atibainha.\n",
    "\n",
    "Tais dados não serão aqui considerados, visto que já se encontram discretizados em dado diário na tabela acima. Logo, **tal função não será aplicada**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura de Transposição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_EEAB(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaEspecial']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "    \n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_vazaoEEAB_pontos = list_EEAB(df_json)\n",
    "#tab_vazaoEEAB_pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vazão de Transposição\n",
    "\n",
    "Dados horários, transferência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vazao_EEAB(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDadosEspecial']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Dados')\n",
    "    \n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_vazaoEEAB = list_vazao_EEAB(df_json)\n",
    "#tab_vazaoEEAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado: Série Histórica do Sistema Cantareira\n",
    "\n",
    "Com todas as funções definidas, é possível aplicar tais funções sequencialmente, visando criar uma série histórica com todos os dados do Sistema Cantareira.\n",
    "\n",
    "Sabendo que a API obtem os dados *até o primeiro dia do mês anterior*, criou-se uma função que monta uma lista de todos os meses e anos a partir de uma data *start*. Posterirmente define-se o dia seguinte ao último dia do mês, ou seja:\n",
    "1. Último dia de um determinado mês [último dia].[mês].[ano];\n",
    "2. Dia seguinte, ou seja, virada de mês, [último dia].[mês].[ano] + 1, que resultará, obrigatoriamente, em [primeiro dia do mês].[mês+1].[ano];\n",
    "\n",
    "Com isso são obtidos do mês anterior e excluído o último dia já do mês subsquente. Como resultado, para cada iteração, teremos o conjunto de dados de um único mês, os quais serão apensados a cada iteração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Série Histórica e Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with start date\n",
    "#start='2020-1-1'\n",
    "#end='2019-12-31'\n",
    "\n",
    "start=datetime.date.today()\n",
    "end=datetime.date.today()\n",
    "\n",
    "\n",
    "df_day, filename_start, filename_end = get_data_tab(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years's List\n",
    "list_year = df_day.index.year\n",
    "list_year = list(set(list_year))\n",
    "list_year = sorted(list_year, reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Loop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zera os Objetos\n",
    "tabs_volumes         = []\n",
    "tabs_vazao           = []\n",
    "tabs_SE              = []\n",
    "tabs_vazaoestruturas = []\n",
    "\n",
    "# Function to loop\n",
    "for y in list_year:\n",
    "    # Tempo\n",
    "    print('Início do ano ' + str(y) + ' as ' + datetime.datetime.now().strftime('%H:%M:%S'))\n",
    "    \n",
    "    # Variáveis de Data\n",
    "    firstdayyear   = datetime.date(y, 1, 1)\n",
    "    lastdayyear    = datetime.date(y, 12, 31)\n",
    "    today          = datetime.date.today()\n",
    "    \n",
    "    if today < lastdayyear:\n",
    "        lastday = today\n",
    "    elif today >= lastdayyear:\n",
    "        lastday = lastdayyear\n",
    "        \n",
    "    # Site\n",
    "    site = ('http://mananciais.sabesp.com.br/api/Mananciais/RepresasSistemasNivel/' + \n",
    "            str(firstdayyear).replace('.','-') + '/' + \n",
    "            str(lastday).replace('.','-') + '/0')\n",
    "        \n",
    "    # Functions\n",
    "    jsn = get_json(site)\n",
    "    time.sleep(30)\n",
    "    df_json = json2table(jsn)\n",
    "    startdate           = get_startdate(df_json)\n",
    "    enddate             = get_enddate(df_json)\n",
    "    tab_manobras        = get_manobras(df_json)\n",
    "    tab_represas        = list_represas(df_json)\n",
    "    \n",
    "    # Dados\n",
    "    tab_volumes         = list_volumes(df_json)\n",
    "    tab_vazao           = list_vazao(df_json)\n",
    "    tab_SE              = list_SE(df_json)\n",
    "    tab_vazaoestruturas = list_vazaoestruturas(df_json)\n",
    "    \n",
    "    # Concat Data\n",
    "    tabs_volumes.append(tab_volumes)\n",
    "    tabs_vazao.append(tab_vazao)\n",
    "    tabs_SE.append(tab_SE)\n",
    "    tabs_vazaoestruturas.append(tab_vazaoestruturas)\n",
    "    \n",
    "# Time\n",
    "print('Fim as ' + datetime.datetime.now().strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conctatena e une tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat Data\n",
    "tabs_volumes         = pd.concat(tabs_volumes)\n",
    "tabs_vazao           = pd.concat(tabs_vazao)\n",
    "tabs_SE              = pd.concat(tabs_SE)\n",
    "tabs_vazaoestruturas = pd.concat(tabs_vazaoestruturas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Table\n",
    "tabs_volumes = pd.concat([tabs_volumes, tabs_vazao], axis=1)\n",
    "tabs_volumes = pd.concat([tabs_volumes, tabs_SE], axis=1)\n",
    "tabs_volumes = pd.concat([tabs_volumes, tabs_vazaoestruturas], axis=1)\n",
    "\n",
    "# Merge\n",
    "df_final = pd.merge(df_day, tabs_volumes, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df_final.dropna(how='all', inplace=True)\n",
    "\n",
    "filename = 'tab_Cantareira_' + filename_start + '_até_' + filename_end + '.csv'\n",
    "df_final.to_csv(os.path.join('data', filename),\n",
    "                index=True,\n",
    "                header=True,\n",
    "                encoding='UTF-8-SIG',\n",
    "                sep=';',\n",
    "                decimal=',',\n",
    "                date_format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
