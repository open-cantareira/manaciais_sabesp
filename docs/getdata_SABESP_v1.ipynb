{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Inicialmente importa-se as bibliotecas que serão necessárias para rodar os códigos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E é criada a estrutura de pastas que serão utilizadas para armazenar os arquivos que serão criados ao longo do processo. Em específico, a pasta *data* é a que armazenará a tabela com as informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"data\" already exists...\n"
     ]
    }
   ],
   "source": [
    "%run '../codes/files/create_folders.py'\n",
    "create_folders('', ['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Série Histórica e Datas\n",
    "\n",
    "A função abaixo retorna três parâmetros:\n",
    "1. Tabela com uma série histórica, com uma data de início e uma data de término.\n",
    "2. Data inicial em formato texto, para ser usada no nome do arquivo que vamos criar.\n",
    "3. Data final em formato texto, para ser usada no nome do arquivo que vamos criar.\n",
    "\n",
    "Caso não seja definida uma data final, será usado o dia de hoje.\n",
    "Importante ter atenção a isso pois a SABESP disponibiliza atualizações dos dados as 9:00 (conforme site deles) e, caso o presente código seja rodado entre a meia noite e as 9:00, tentar-se-á obter informações não disponíveis, possivelmnete gerando erros. Para contornar isso, é possível inserir um parâmetro como *dia de hoje - 1*, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tab(start='1970-1-1', end=None):\n",
    "    \"\"\"\n",
    "    Function to create date table, with only on colum named 'Data' as index.\n",
    "    With no 'end' parameter is passed, the function will return a table until today\n",
    "    With no 'start' parameter is passed, the function will return a table staring in firts day of de 70's.\n",
    "    \n",
    "    The function return two more parameters to used in filenames:\n",
    "    filename_start > first day of table \n",
    "    filename_end   > last day of table as string\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Dataframe to get dates\n",
    "    if end is None:\n",
    "        df = pd.DataFrame(pd.date_range(pd.to_datetime(start), end=datetime.date.today()), columns=['Data'])\n",
    "        filename_start = str(datetime.datetime.strptime(str(start), '%Y-%m-%d').strftime('%Y-%m-%d'))\n",
    "        filename_end   = str(datetime.datetime.strptime(str(datetime.date.today()), '%Y-%m-%d').strftime('%Y-%m-%d'))\n",
    "    \n",
    "    else:\n",
    "        df = pd.DataFrame(pd.date_range(pd.to_datetime(start), end=pd.to_datetime(end)), columns=['Data'])\n",
    "        filename_start = str(datetime.datetime.strptime(str(start), '%Y-%m-%d').strftime('%Y.%m.%d'))\n",
    "        filename_end   = str(datetime.datetime.strptime(str(end), '%Y-%m-%d').strftime('%Y.%m.%d'))\n",
    "\n",
    "    # Results\n",
    "    df = df.set_index('Data')\n",
    "    return df, filename_start, filename_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2020-1-1'\n",
    "df_day, filename_start, filename_end = get_data_tab(start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end='2020-3-28'\n",
    "#end=str(datetime.date.today()-datetime.timedelta(days=1))\n",
    "#df_day, filename_start, filename_end = get_data_tab(start=start, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Link* para fazer o *download* do Json\n",
    "\n",
    "Inicialmente foram feitas tentativas diversas para melhor conhecimento do [*site* da SABESP](http://mananciais.sabesp.com.br/HistoricoSistemas?SistemaId=0) que disponibiliza as informações dos mananciais. Inicialmente tentou-se obter os dados pela técnica de *web scrapping*, até que descobriu-se que os dados são distribuídos por meio de uma API do SSD (Sistema de Suporte a Decisões).\n",
    "\n",
    "Observou-se que a consulta manual apresenta os dados do mês da presente data até o primeiro dia do mês anterior. Por exemplo, se estamos no dia 25.**03**.2020, os dados apresentados serão dessa data até o dia 01.**02**.2020, retornando aproximadamente dados de 55 dias (30 dias de um mês hipotético e 25 do outro). O mesmo padrão irá ocorrer caso a consulta seja feita em 01.**03**.2020, a qual retornar-a os dados *até o primeiro dia do mês anterior*, ou seja, 01.**02**.2020.\n",
    "\n",
    "Essa forma de \"entregar\" os dados foi considerada na requisição de dados pela API, a qual foi feita com uso do [urllib.request](https://stackoverflow.com/questions/32795460/loading-json-object-in-python-using-urllib-request-and-json-modules). A API tem seu *link* padrão apresentado abaixo, sendo inserido apenas duas variáveis: a data e o Sistema (aqui representado pelo 0 no final, que representa o Sistema Produtor Cantareira).\n",
    "\n",
    "- http://mananciais.sabesp.com.br/api/Mananciais/RepresasSistemasNivel/2020-03-25/0\n",
    "\n",
    "*ToDo*: O Presente código tem a finalidade de obter os dados unicamente do Sistema Cantareira e, portanto, não se pensou em adicionar a possibilidade de obter os dados dos outros sistemas produtores, por meio da inclusão e ajuste desse parâmetro definido e fixado como *0*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://mananciais.sabesp.com.br/api/Mananciais/RepresasSistemasNivel/2020-04-18/0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site = ('http://mananciais.sabesp.com.br/api/Mananciais/RepresasSistemasNivel/' +\n",
    "        str(filename_end.replace('.','-')) +\n",
    "        '/0')\n",
    "site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o *link* da API com uma data definida, criou-se uma função para obter os dados em formato *json*, bastanto inserir o site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url):\n",
    "    # Get Array with data\n",
    "    webURL = urllib.request.urlopen(site)\n",
    "    my_bytes = webURL.read()\n",
    "\n",
    "    # Transform Array into JSON\n",
    "    my_json = my_bytes.decode('utf8')\n",
    "    data = json.loads(my_json)\n",
    "    return json.dumps(data, indent=2, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsn = get_json(site)\n",
    "#print(jsn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertendo Json para tabela e extraíndo dados\n",
    "\n",
    "Com o arquivo Json contendo todos os dados de mais de um mês atrás, segmentado em diversas chaves e subchaves, iniciou-se a segmentação do arquivo, convertendo o arquivo para uma tabela, com a qual tenho mais familiaridade para editar e filtrar.\n",
    "\n",
    "A função abaixo tem essa aplicação e já aproveita para excluir duas colunas que, aparentemente, não agregam informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2table(jsn):\n",
    "    # Create dataframe\n",
    "    df = pd.read_json(jsn)\n",
    "\n",
    "    # Delete columns\n",
    "    return df.drop(['FlagHasError', 'Message'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = json2table(jsn)\n",
    "#df_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema Produtor\n",
    "\n",
    "Por meio do campo *SistemaId* é possível obter o código que define qual é o sistema produtor de água. Contudo, considerando que o presente *script* visa obter somente os dados do Sistema Cantareira, **tal função não será aplicada**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_json.loc['SistemaId']['ReturnObj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Final\n",
    "\n",
    "Identifica data empregada na API, a partir da qual se obterá os dados *até o primeiro dia do mês anterior*. Não se vislumbra muita utilidade para essa informação nesse momento, tendo em vista que foi o usuário que definiu esse parâmetro na definição do *link* de acesso à API. Logo, **tal função não será aplicada**.\n",
    "\n",
    "Cabe ressaltar que tal função é chamada em outras funções, para se obter a data do último registro da tabela, qu poderá, ou não, ser excluído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(df):\n",
    "    # JSON to dataframe    \n",
    "    data = df_json.loc['Data']['ReturnObj']   \n",
    "    \n",
    "    # Results\n",
    "    return pd.to_datetime(data, dayfirst=True).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = get_date(df_json)\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manobras Operacionais\n",
    "\n",
    "Identifica todas as manobras listadas no site da SABESP. São dados mais descritivos, disponibilizados visando dar mais transparência a cadeia de comando para abrir ou fechar os reservatórios. Nesse primeiro momento tais dados não serão analisado e, portanto, **tal função não será aplicada**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manobras(df):\n",
    "    # JSON to dataframe    \n",
    "    lst = df.loc['ListaManobras']['ReturnObj']\n",
    "    \n",
    "    # Results\n",
    "    return pd.json_normalize(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_manobras = get_manobras(df_json)\n",
    "#df_manobras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes do Sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservatórios\n",
    "\n",
    "A função abaixo lista os reservatórios (ou represas) do Sistema Cantareira e outras que estão integradas, de alguma maneira, ao Sistema, inserindo também o identificador de cada reservatório (*ComponenteId*).\n",
    "\n",
    "Apesar de trata-se de uma tabela que não retorna dados temporais (por exemplo: vazão, volume e chuva), ou seja, que variam ao longo do tempo, é fundamental para rotular de qual reservatório que são os dados temporais que serão obtidos nas próximas funções, visto que eles se valem, majoritariamente, do campo *ComponenteId*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_represas(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaRepresas']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "\n",
    "    # Delete columns\n",
    "    df = df.drop(['temChuva','temNivel', 'temQjus', 'temQnat', 'temVolume'], axis=1)\n",
    "\n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ComponenteId</th>\n",
       "      <th>Nome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Represa Jaguari/Jacareí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Represa Cachoeira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Represa Atibainha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Represa Paiva Castro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Represa Águas Claras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>Represa Jaguari (Cesp)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ComponenteId                     Nome\n",
       "0             1  Represa Jaguari/Jacareí\n",
       "1             3        Represa Cachoeira\n",
       "2             4        Represa Atibainha\n",
       "3             5     Represa Paiva Castro\n",
       "4             6     Represa Águas Claras\n",
       "5            35   Represa Jaguari (Cesp)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_represas = list_represas(df_json)\n",
    "tab_represas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estruturas (Túneis e outros Pontos de Medição)\n",
    "\n",
    "A função abaixo lista os túneis e estações de monitoramento do Sistema Cantareira e outras que estão integradas, de alguma maneira, ao Sistema, inserindo também o identificador de cada local (*ComponenteId*).\n",
    "\n",
    "Apesar de trata-se de uma tabela que não retorna dados temporais (por exemplo: vazão, volume e chuva), ou seja, que variam ao longo do tempo, contudo é fundamental para rotular de qual estrutura que são os dados temporais que serão obtidos nas próximas funções, visto que eles se valem, majoritariamente, do campo *ComponenteId* ou *abreviatura*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_estruturas(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaLocais']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "\n",
    "    # Delete columns\n",
    "    df = df.drop(['Maximo','Minimo',\n",
    "                  'Data','Dia',\n",
    "                  'Valor','Unidade'],\n",
    "                 axis=1)\n",
    "\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('ComponenteId')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ComponenteId</th>\n",
       "      <th>Abreviatura</th>\n",
       "      <th>LocalMedicaoId</th>\n",
       "      <th>Nome</th>\n",
       "      <th>SistemaId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>F-25bT</td>\n",
       "      <td>46</td>\n",
       "      <td>F-25bT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Q T5</td>\n",
       "      <td>10</td>\n",
       "      <td>Q Túnel 5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Q T6</td>\n",
       "      <td>9</td>\n",
       "      <td>Q Túnel 6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Q T7</td>\n",
       "      <td>7</td>\n",
       "      <td>Q Túnel 7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Q ESI</td>\n",
       "      <td>11</td>\n",
       "      <td>Q Elev. Santa Inês</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.0</td>\n",
       "      <td>Q PS-SC</td>\n",
       "      <td>47</td>\n",
       "      <td>Q Transf Paraíba do Sul - Atibainha (PS-SC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.0</td>\n",
       "      <td>Q SC-PS</td>\n",
       "      <td>48</td>\n",
       "      <td>Q Transf Atibainha - Paraíba do Sul (SC-PS)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ComponenteId Abreviatura  LocalMedicaoId  \\\n",
       "0           NaN      F-25bT              46   \n",
       "1           7.0        Q T5              10   \n",
       "2           8.0        Q T6               9   \n",
       "3           9.0        Q T7               7   \n",
       "4          36.0       Q ESI              11   \n",
       "5          48.0     Q PS-SC              47   \n",
       "6          49.0     Q SC-PS              48   \n",
       "\n",
       "                                          Nome  SistemaId  \n",
       "0                                       F-25bT          0  \n",
       "1                                    Q Túnel 5          0  \n",
       "2                                    Q Túnel 6          0  \n",
       "3                                    Q Túnel 7          0  \n",
       "4                           Q Elev. Santa Inês          0  \n",
       "5  Q Transf Paraíba do Sul - Atibainha (PS-SC)          0  \n",
       "6  Q Transf Atibainha - Paraíba do Sul (SC-PS)          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_estruturas = list_estruturas(df_json)\n",
    "tab_estruturas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Diários\n",
    "\n",
    "Nessa seção que serão obtidos diversos dados relevantes na operação do Sistema Cantareira, tais como:\n",
    "- Vazão natural em cada reservatório;\n",
    "- Vazão afluente em cada reservatório;\n",
    "- Vazão defluente em cada reservatório;\n",
    "- Nível e Volume de cada reservatório;\n",
    "- Dados de Precipitação de cada reservatório.\n",
    "\n",
    "Inicialmente, definiu-se uma função para renomear *strings*, visto que estas constarão nos cabeçalhos das tabelas a serem criadas. Aplicou-se a função na *tab_represas* (criada acima) apenas para observar quais serão os nomes que constarão no cabeçalho das tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_field(x):\n",
    "    return(x.replace('/', '-').\n",
    "           replace(' (', '-').\n",
    "           replace(')', '').\n",
    "           replace('Cesp', 'CESP').\n",
    "           replace('Represa ', '').\n",
    "           replace(' ', '')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ComponenteId</th>\n",
       "      <th>Nome</th>\n",
       "      <th>Nome_Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Represa Jaguari/Jacareí</td>\n",
       "      <td>Jaguari-Jacareí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Represa Cachoeira</td>\n",
       "      <td>Cachoeira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Represa Atibainha</td>\n",
       "      <td>Atibainha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Represa Paiva Castro</td>\n",
       "      <td>PaivaCastro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Represa Águas Claras</td>\n",
       "      <td>ÁguasClaras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>Represa Jaguari (Cesp)</td>\n",
       "      <td>Jaguari-CESP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ComponenteId                     Nome      Nome_Header\n",
       "0             1  Represa Jaguari/Jacareí  Jaguari-Jacareí\n",
       "1             3        Represa Cachoeira        Cachoeira\n",
       "2             4        Represa Atibainha        Atibainha\n",
       "3             5     Represa Paiva Castro      PaivaCastro\n",
       "4             6     Represa Águas Claras      ÁguasClaras\n",
       "5            35   Represa Jaguari (Cesp)     Jaguari-CESP"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tab_represas\n",
    "t['Nome_Header'] = t['Nome'].apply(lambda x: rename_field(x))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume, QJusante e Chuva\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDados* e subchave *Dados*, foi obtido os dados de volume, vazão defluente e precpitação de cada reservatório.\n",
    "\n",
    "No arquivo json, as tabelas encontravam-se empilhadas (*flat table*), com uma coluna com o nome do reservatório. Portanto, foi necessário filtrar essas tabelas por reservatório, ajustar o cabeçalho inserindo o nome do reservatório em questão e, posteriromente, fazer um join das tabelas pelo campo *data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_volumes(df_json, keep_lastline=False):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDados']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Dados')\n",
    "\n",
    "    # Define pivot to create new tables\n",
    "    fields = df['Nome']\n",
    "    fields = sorted(list(set(fields)))\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('Data')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Create a blank table\n",
    "    df_full,start,end = get_data_tab()\n",
    "\n",
    "    for i in fields:\n",
    "        # Define Nomes e Nomes de Tabelas\n",
    "        j = rename_field(i)\n",
    "        tab_name = 'tab_dados' + '_' + j\n",
    "        \n",
    "        # Filtra e cria das tabelas por fields (represas)\n",
    "        locals()[tab_name] = df[df['Nome'] == i]\n",
    "\n",
    "        # Deleta colunas\n",
    "        locals()[tab_name] = locals()[tab_name].drop(['FlagConsolidado',\n",
    "                                                      'NAMaxMax','NAMinMin',\n",
    "                                                      'QJusanteMax','QJusanteMin',\n",
    "                                                      'NivelUltimoDia',\n",
    "                                                      'SistemaId','ComponenteId',\n",
    "                                                      'UltimoDia',\n",
    "                                                      'VazaoJusantePrincipal','VazaoJusanteSecundaria',\n",
    "                                                      'VolumeOperacionalUltimoDia','VolumePorcentagemUltimoDia',\n",
    "                                                      'VolumeTotalUltimoDia','Nome'], axis=1)\n",
    "\n",
    "        # Renomeia as colunas\n",
    "        locals()[tab_name].columns = [x if x=='Data' else j+'_'+x for x in locals()[tab_name].columns]\n",
    "\n",
    "        # Convert Data Column (object) to datatime colum\n",
    "        locals()[tab_name]['Data'] = pd.to_datetime(locals()[tab_name]['Data'])\n",
    "\n",
    "        # Merge all tables\n",
    "        df_full = pd.merge(df_full,locals()[tab_name],on='Data',how='left')\n",
    "\n",
    "    # Results\n",
    "    df_full = df_full.set_index('Data')\n",
    "    df_full.dropna(how='all', inplace=True)\n",
    "    \n",
    "    if not(keep_lastline):\n",
    "        data = get_date(df_json)\n",
    "        df_full.drop(pd.Timestamp(data), axis=0, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/pablocarreira-py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-bdc33b52e12c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtab_volumes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_volumes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtab_volumes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-32d991dbf802>\u001b[0m in \u001b[0;36mlist_volumes\u001b[0;34m(df_json, keep_lastline)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_lastline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mdf_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4584711b1746>\u001b[0m in \u001b[0;36mget_date\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# JSON to dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ReturnObj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pablocarreira-py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pablocarreira-py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pablocarreira-py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pablocarreira-py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3537\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pablocarreira-py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Data'"
     ]
    }
   ],
   "source": [
    "tab_volumes = list_volumes(df_json, False)\n",
    "tab_volumes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vazão Afluente e Vazão Natural\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDados* e subchave *Qnat*, foram obtido os dados de vazão afluente e vazão naturalde cada reservatório.\n",
    "\n",
    "No arquivo json, as tabelas encontravam-se empilhadas (*flat table*), com uma coluna com o nome do reservatório. Portanto, foi necessário filtrar essas tabelas por reservatório, ajustar o cabeçalho inserindo o nome do reservatório em questão e, posteriromente, fazer um join das tabelas pelo campo *data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vazao(df_json, keep_lastline=False):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDados']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Qnat')\n",
    "\n",
    "    # Merge Tables\n",
    "    df = pd.merge(df, tab_represas, on='ComponenteId', how='outer')\n",
    "\n",
    "    # Define pivot to create new tables\n",
    "    fields = df['Nome']\n",
    "    fields = sorted(list(set(fields)))\n",
    "    \n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('Data')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Create a blank table\n",
    "    df_full,start,end = get_data_tab()\n",
    "\n",
    "    for i in fields:\n",
    "        # Define Nomes e Nomes de Tabelas\n",
    "        j = rename_field(i)\n",
    "        tab_name = 'tab_vazaonatural'+'_'+j\n",
    "        \n",
    "        # Filtra e cria das tabelas por fields (represas)\n",
    "        locals()[tab_name] = df[df['Nome'] == i]\n",
    "\n",
    "        # Deleta colunas\n",
    "        locals()[tab_name] = locals()[tab_name].drop(['ComponenteId','Nome',\n",
    "                                                      'VazaoAfluenteMax','VazaoAfluenteMin',\n",
    "                                                      'VazaoNaturalMax','VazaoNaturalMin'],axis=1)\n",
    "\n",
    "        # Renomeia as colunas\n",
    "        locals()[tab_name].columns = [x if x=='Data' else j+'_'+x for x in locals()[tab_name].columns]\n",
    "\n",
    "        # Convert Data Column (object) to datatime colum\n",
    "        locals()[tab_name]['Data'] = pd.to_datetime(locals()[tab_name]['Data'])\n",
    "\n",
    "        # Merge all tables\n",
    "        df_full = pd.merge(df_full,locals()[tab_name], on='Data', how='left')\n",
    "\n",
    "    # Results\n",
    "    df_full = df_full.set_index('Data')\n",
    "    df_full.dropna(how='all', inplace=True)\n",
    "    \n",
    "    if not(keep_lastline):\n",
    "        data = get_date(df_json)\n",
    "        df_full.drop(pd.Timestamp(data), axis=0, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_vazao = list_vazao(df_json, False)\n",
    "tab_vazao.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sistema Equivalente\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDados*, foram obtido os dados do Sistema Equivalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_SE(df_json, keep_lastline=False):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDados']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "\n",
    "    # Delete columns\n",
    "    df = df.drop(['Dados','Data','Qnat'], axis=1)\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "\n",
    "    # Functions to rename\n",
    "    col = ['SE_'+x for x in col]\n",
    "    col = [x.replace('SistemaEquivalente.', '').replace('SE_Data', 'Data') for x in col]\n",
    "\n",
    "    # Rename Columns\n",
    "    df.columns = col\n",
    "\n",
    "    # Convert Data Column (object) to datatime colum\n",
    "    df['Data'] = pd.to_datetime(df['Data'])\n",
    "\n",
    "    # Results\n",
    "    df = df.set_index('Data')\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    if not(keep_lastline):\n",
    "        data = get_date(df_json)\n",
    "        df.drop(pd.Timestamp(data), axis=0, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_SE = list_SE(df_json, False)\n",
    "tab_SE.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vazão dos Túneis e outros Pontos de Medição\n",
    "\n",
    "Extraíndo os dados do json, por meio da chave *ListaDadosLocais* e subchave *Dados*, foram obtido os dados de vazão dos túneis Q7, Q6 Q5 e outros.\n",
    "\n",
    "No arquivo json, as tabelas encontravam-se empilhadas (*flat table*), com uma coluna com o nome da estrutura. Portanto, foi necessário filtrar essas tabelas por estrutura, adicionando ao cabeçalho seu repectivo nome e, posteriormente, fazer um join das tabelas pelo campo *data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vazaoestruturas(df_json, keep_lastline=False):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDadosLocais']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Dados')\n",
    "\n",
    "    # Define pivot to create new tables\n",
    "    fields = df['Abreviatura']\n",
    "    fields = sorted(list(set(fields)))\n",
    "\n",
    "    # Transform columns to list and reorder list\n",
    "    col = df.columns.to_list()\n",
    "    col.insert(0, col.pop(col.index('Data')))\n",
    "    col.append(col.pop(col.index('Unidade')))\n",
    "\n",
    "    # Reindex Columns\n",
    "    df = df.reindex(columns=col)\n",
    "\n",
    "    # Create a blank table\n",
    "    df_full,start,end = get_data_tab()\n",
    "\n",
    "    for i in fields:\n",
    "        # Define Nomes e Nomes de Tabelas\n",
    "        j = rename_field(i)\n",
    "        tab_name = 'tab_dados' + '_' + j\n",
    "        \n",
    "        # Filtra e cria das tabelas por fields (represas)\n",
    "        locals()[tab_name] = df[df['Abreviatura'] == i]\n",
    "\n",
    "        # Deleta colunas\n",
    "        locals()[tab_name] = locals()[tab_name].drop(['Maximo', 'Minimo', 'Dia', 'Abreviatura', 'ComponenteId', 'LocalMedicaoId', 'Nome', 'SistemaId'],axis=1)\n",
    "\n",
    "        # Renomeia as colunas\n",
    "        locals()[tab_name].columns = [x if x=='Data' else j+'_'+x for x in locals()[tab_name].columns]\n",
    "\n",
    "        # Convert Data Column (object) to datatime colum\n",
    "        locals()[tab_name]['Data'] = pd.to_datetime(locals()[tab_name]['Data'])\n",
    "\n",
    "        # Merge all tables\n",
    "        df_full = pd.merge(df_full,locals()[tab_name],on='Data',how='left')\n",
    "\n",
    "    # Results\n",
    "    df_full = df_full.set_index('Data')\n",
    "    df_full.dropna(how='all', inplace=True)\n",
    "    \n",
    "    if not(keep_lastline):\n",
    "        data = get_date(df_json)\n",
    "        df_full.drop(pd.Timestamp(data), axis=0, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_vazaoestruturas = list_vazaoestruturas(df_json, False)\n",
    "tab_vazaoestruturas.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Horários\n",
    "\n",
    "Referem-se a transposição da bacia do rio Paraíba do Sul para a bacia do rio Piracicaba, por meio da Estação Elevatória de Água Bruta (EEAB) Jaguari, que despeja água na represa Atibainha.\n",
    "\n",
    "Tais dados não serão aqui considerados, visto que já se encontram discretizados em dado diário na tabela acima. Logo, **tal função não será aplicada**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura de Transposição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_EEAB(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaEspecial']['ReturnObj']\n",
    "    df = pd.json_normalize(lst)\n",
    "    \n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_vazaoEEAB_pontos = list_EEAB(df_json)\n",
    "#tab_vazaoEEAB_pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vazão de Transposição\n",
    "\n",
    "Dados horários, transferência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_vazao_EEAB(df_json):\n",
    "    # JSON to dataframe\n",
    "    lst = df_json.loc['ListaDadosEspecial']['ReturnObj']\n",
    "    df = pd.json_normalize(lst, 'Dados')\n",
    "    \n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_vazaoEEAB = list_vazao_EEAB(df_json)\n",
    "#tab_vazaoEEAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado: Série Histórica do Sistema Cantareira\n",
    "\n",
    "Com todas as funções definidas, é possível aplicar tais funções sequencialmente, visando criar uma série histórica com todos os dados do Sistema Cantareira.\n",
    "\n",
    "Sabendo que a API obtem os dados *até o primeiro dia do mês anterior*, criou-se uma função que monta uma lista de todos os meses e anos a partir de uma data *start*. Posterirmente define-se o dia seguinte ao último dia do mês, ou seja:\n",
    "1. Último dia de um determinado mês [último dia].[mês].[ano];\n",
    "2. Dia seguinte, ou seja, virada de mês, [último dia].[mês].[ano] + 1, que resultará, obrigatoriamente, em [primeiro dia do mês].[mês+1].[ano];\n",
    "\n",
    "Com isso são obtidos do mês anterior e excluído o último dia já do mês subsquente. Como resultado, para cada iteração, teremos o conjunto de dados de um único mês, os quais serão apensados a cada iteração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Série Histórica e Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with start date\n",
    "start='1990-1-1'\n",
    "df_day, filename_start, filename_end = get_data_tab(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with start and end date\n",
    "#end='2000-1-1'\n",
    "#end=datetime.date.today()\n",
    "#end=str(datetime.date.today()-datetime.timedelta(days=1))\n",
    "#df_day, filename_start, filename_end = get_data_tab(start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years's List\n",
    "list_year = df_day.index.year\n",
    "list_year = list(set(list_year))\n",
    "list_year = sorted(list_year, reverse = True)\n",
    "\n",
    "# Month's List\n",
    "list_month = df_day.index.month\n",
    "list_month = list(set(list_month))\n",
    "list_month = sorted(list_month, reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Loop*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zera os Objetos\n",
    "tabs_volumes         = []\n",
    "tabs_vazao           = []\n",
    "tabs_SE              = []\n",
    "tabs_vazaoestruturas = []\n",
    "\n",
    "# Function to loop\n",
    "for y in list_year:\n",
    "    for m in list_month:\n",
    "        # Variáveis de Data\n",
    "        lastday    = calendar.monthrange(y, m)[1]\n",
    "        date       = datetime.date(y, m, lastday)\n",
    "        date_site  = datetime.date(y, m, lastday)+datetime.timedelta(days=1)\n",
    "        today      = datetime.date.today()\n",
    "        \n",
    "        if date_site < today:\n",
    "            if date_site.month == today.month and date_site.year == today.year:\n",
    "                day = today\n",
    "                keep_lastline=True\n",
    "                print(str(datetime.datetime.now().time())+' | '+str(day) + ' > Dados de hoje até inicio do mês anterior > keep_lastline='+str(keep_lastline))\n",
    "        \n",
    "            elif date_site.month != today.month or date_site.year != today.year:\n",
    "                day = date_site\n",
    "                keep_lastline=False\n",
    "                print(str(datetime.datetime.now().time())+' | '+str(day) + ' > Dados do mês anterior > keep_lastline='+str(keep_lastline))\n",
    "\n",
    "                # Site\n",
    "                site = 'http://mananciais.sabesp.com.br/api/Mananciais/RepresasSistemasNivel/' + str(day) + '/0'\n",
    "\n",
    "            # Functions\n",
    "            jsn = get_json(site)\n",
    "            time.sleep(30)\n",
    "            df_json = json2table(jsn)\n",
    "            #data = get_date(df_json)\n",
    "            tab_manobras = get_manobras(df_json)\n",
    "            tab_represas = list_represas(df_json)\n",
    "\n",
    "            # Dados\n",
    "            tab_volumes         = list_volumes(df_json, keep_lastline)\n",
    "            tab_vazao           = list_vazao(df_json, keep_lastline)\n",
    "            tab_SE              = list_SE(df_json, keep_lastline)\n",
    "            tab_vazaoestruturas = list_vazaoestruturas(df_json, keep_lastline)\n",
    "\n",
    "            # Concat Data\n",
    "            tabs_volumes.append(tab_volumes)\n",
    "            tabs_vazao.append(tab_vazao)\n",
    "            tabs_SE.append(tab_SE)\n",
    "            tabs_vazaoestruturas.append(tab_vazaoestruturas)\n",
    "\n",
    "        elif date_site > today:\n",
    "            day = date_site\n",
    "            print(str(day) + ' > Data que não atende condições')\n",
    "            \n",
    "        else:\n",
    "            print('Erro')\n",
    "            \n",
    "print('Fim!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conctatena e une tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat Data\n",
    "tabs_volumes         = pd.concat(tabs_volumes)\n",
    "tabs_vazao           = pd.concat(tabs_vazao)\n",
    "tabs_SE              = pd.concat(tabs_SE)\n",
    "tabs_vazaoestruturas = pd.concat(tabs_vazaoestruturas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Table\n",
    "tabs_volumes = pd.concat([tabs_volumes, tabs_vazao], axis=1)\n",
    "tabs_volumes = pd.concat([tabs_volumes, tabs_SE], axis=1)\n",
    "tabs_volumes = pd.concat([tabs_volumes, tabs_vazaoestruturas], axis=1)\n",
    "\n",
    "# Merge\n",
    "df_final = pd.merge(df_day, tabs_volumes, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df_final.dropna(how='all', inplace=True)\n",
    "\n",
    "filename='tab_Cantareira_'+filename_end+'_até_'+filename_start+'.csv'\n",
    "df_final.to_csv(os.path.join('data', filename),\n",
    "                     index=True,\n",
    "                     header=True,\n",
    "                     sep=';',\n",
    "                     date_format='%d/%m/%Y',\n",
    "                     decimal=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pablocarreira-lastest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:30:19) [MSC v.1929 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "4d2082c677fdf35794c222228cc7f22d43df5b8d8a9da3c3f9d9c2f356a8965c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
